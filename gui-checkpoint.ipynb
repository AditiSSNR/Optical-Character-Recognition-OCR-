{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcac2f6-e43b-4dfc-946c-c1adc83cd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e1e39a-fe2b-4f78-9fcb-58af6ea2865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_canvas():\n",
    "    model = load_model('ocr.h5')\n",
    "    # Create a black canvas\n",
    "    canvas = np.zeros((300, 300), dtype=np.uint8)\n",
    "    drawing = False\n",
    "    last_x, last_y = None, None\n",
    "    predicted_digit = None\n",
    "\n",
    "    def draw(event, x, y, flags, param):\n",
    "        nonlocal drawing, last_x, last_y, canvas, predicted_digit\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True\n",
    "            last_x, last_y = x, y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing:\n",
    "                cv2.line(canvas, (last_x, last_y), (x, y), 255, 20)\n",
    "                last_x, last_y = x, y\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            drawing = False\n",
    "            # Predict the digit when the user stops drawing\n",
    "            digit_image = canvas.copy()\n",
    "            digit_image = cv2.resize(digit_image, (28, 28))  # Resize to match input shape of the model\n",
    "            digit_image = cv2.dilate(digit_image, None, iterations=1)  # Enhance thickness\n",
    "            digit_image = cv2.erode(digit_image, None, iterations=1)  # Clean up\n",
    "            digit_image = digit_image.flatten().reshape(1, 28, 28, 1)  # Reshape for the model\n",
    "            digit_image = digit_image.astype('float32') / 255  # Normalize image\n",
    "\n",
    "            # Predict the digit\n",
    "            predicted_digit = model.predict(digit_image)\n",
    "            predicted_digit = np.argmax(predicted_digit, axis=1)  # Get the index of the predicted class\n",
    "    \n",
    "    # Set up the window and the mouse callback function\n",
    "    cv2.namedWindow(\"Handwritten Digit Recognition\")\n",
    "    cv2.setMouseCallback(\"Handwritten Digit Recognition\", draw)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Handwritten Digit Recognition\", canvas)\n",
    "\n",
    "        # If a digit is predicted, display the result in a separate window\n",
    "        if predicted_digit is not None:\n",
    "            output = np.zeros((400, 400), dtype=np.uint8)  # Increased window size\n",
    "            cv2.putText(output, f\"Predicted: {predicted_digit[0]}\", (50, 200),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"Prediction\", output)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Check for user input to either clear the canvas or quit\n",
    "        if key == ord('q'):  # Press 'Q' to quit\n",
    "            break\n",
    "        elif key == ord('c'):  # Press 'C' to clear the canvas\n",
    "            canvas = np.zeros((300, 300), dtype=np.uint8)\n",
    "            predicted_digit = None\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bd0fd2-cc02-4d05-9faf-87b79c2237d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_capture():\n",
    "    # Initialize webcam\n",
    "    model = load_model('ocr.h5')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        # Draw rectangles around the faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            # Display \"Hello!!!\" and a smiley emoji near the face\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, \"Hello!!!\", (x, y - 10), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display a smiley emoji (use a simple smiley character as text or use a custom image)\n",
    "            smiley = \":)\"  # You can use a more advanced emoji display here, but for simplicity, we'll use text\n",
    "            cv2.putText(frame, smiley, (x + w - 30, y + h + 30), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Apply Gaussian Blur\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Thresholding\n",
    "        ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw bounding box and extract ROI\n",
    "        for contour in contours:\n",
    "            # Calculate bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Create a square ROI\n",
    "            if w >= 20 and h >= 20:\n",
    "                roi = thresh[y:y+h, x:x+w]\n",
    "                roi = cv2.resize(roi, (28, 28))  # Resize to match MNIST input size\n",
    "                roi = roi.reshape(1, 28, 28, 1) / 255.0  # Normalize and reshape\n",
    "\n",
    "                # Predict digit\n",
    "                prediction = model.predict(roi)\n",
    "                digit = np.argmax(prediction)\n",
    "\n",
    "                # Check prediction confidence\n",
    "                confidence = np.max(prediction)\n",
    "                if confidence > 0.8:  # Adjust confidence threshold as needed\n",
    "                    # Draw bounding box and display predicted digit\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, str(digit), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Handwritten Digit Recognition', frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d59434e-709a-40c8-ad79-60e737bf0763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Load the pre-trained OCR model (ensure the model file is in the correct location)\n",
    "model = load_model('ocr.h5')\n",
    "\n",
    "# Function to process image and predict the handwritten digit\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image using OpenCV in grayscale\n",
    "    org_img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(org_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize the image to match the input size expected by the model (28x28 for MNIST-like models)\n",
    "    img_resized = cv2.resize(img, (28, 28))\n",
    "\n",
    "    # Normalize the image by dividing by 255.0\n",
    "    img_normalized = img_resized / 255.0\n",
    "\n",
    "    # Reshape the image for the model (model expects a batch of images)\n",
    "    img_reshaped = img_normalized.reshape(1, 28, 28, 1)\n",
    "\n",
    "    # Predict the digit using the model\n",
    "    prediction = model.predict(img_reshaped)\n",
    "\n",
    "    # Get the predicted digit (the class with the highest probability)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "    \n",
    "    return predicted_digit, org_img  # Return the predicted digit and original image\n",
    "\n",
    "# Function to open the file explorer and choose an image\n",
    "def choose_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.tiff\")])\n",
    "    if file_path:\n",
    "        try:\n",
    "            # Process and predict the handwritten digit from the image\n",
    "            predicted_digit, original_img = preprocess_image(file_path)\n",
    "\n",
    "            # Display the result in a new window\n",
    "            result_window(predicted_digit, original_img)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred while processing the image: {str(e)}\")\n",
    "\n",
    "# Function to create a result window to display the predicted digit and original image\n",
    "def result_window(predicted_digit, original_img):\n",
    "    result_window = tk.Toplevel(window)\n",
    "    result_window.title(\"Prediction Result\")\n",
    "\n",
    "    # Display the predicted digit\n",
    "    label = tk.Label(result_window, text=f\"Predicted Handwritten Digit: {predicted_digit}\", font=(\"Arial\", 20))\n",
    "    label.pack(pady=10)\n",
    "\n",
    "    # Convert the image from OpenCV (BGR) to RGB for Pillow\n",
    "    original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to a Pillow Image\n",
    "    pil_image = Image.fromarray(original_img_rgb)\n",
    "\n",
    "    # Resize the image for better display in the window\n",
    "    pil_image_resized = pil_image.resize((200, 200))\n",
    "\n",
    "    # Display the original image in the window\n",
    "    img_tk = ImageTk.PhotoImage(pil_image_resized)\n",
    "    img_label = tk.Label(result_window, image=img_tk)\n",
    "    img_label.image = img_tk  # Keep a reference to the image\n",
    "    img_label.pack(pady=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0f4471a-2683-4db2-a0e3-356232b6172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "window = Tk()\n",
    "window.title(\"Handwritten digit recognition\")\n",
    "l1 = Label()\n",
    "lastx, lasty = None, None\n",
    "\n",
    "\n",
    "# Label\n",
    "L1 = Label(window, text=\"Optical Character Recognition (OCR) of Digits\", font=('Algerian', 20), fg=\"dark blue\")\n",
    "L1.place(x=35, y=10)\n",
    "L2 = Label(window, text=\"Handwritten Digit Recoginition\", font=('Algerian', 18), fg=\"black\")\n",
    "L2.place(x=145, y=70)\n",
    "\n",
    "b2 = Button(window, text=\"1. Choose Image\", font=(\"Arial\", 15), bg=\"white\", fg=\"red\", command=choose_image)\n",
    "b2.place(x=290, y=180)\n",
    "\n",
    "# Button to predict digit drawn on canvas\n",
    "b2 = Button(window, text=\"2. Write on canvas\", font=('Arial', 15), bg=\"white\", fg=\"red\", command=draw_canvas)\n",
    "b2.place(x=280, y=280)\n",
    "\n",
    "# Button to predict digit drawn on canvas\n",
    "b2 = Button(window, text=\"3. Predict\", font=('Arial', 15), bg=\"white\", fg=\"red\", command=camera_capture)\n",
    "b2.place(x=320, y=380)\n",
    "\n",
    "# Setting properties of canvas\n",
    "#cv = Canvas(window, width=350, height=290, bg='black')\n",
    "#cv.place(x=120, y=70)\n",
    "\n",
    "#cv.bind('<Button-1>', event_activation)\n",
    "window.geometry(\"700x500\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b40f8-1166-401a-a813-7f504f50e60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
